{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5TdwwOR2u6RjVJi32ghZN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pitarac/PucRio_Sprint_02_MVP/blob/main/Parte_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e8pUfh3K-Je"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parte II **\n",
        "\n",
        "#\n",
        "\n",
        "## Identificação\n",
        "\n",
        "**Nome do aluno:** Paulo Henrique Lima da Silva CPF: 032.838.091-19<br>\n",
        "**Disciplina:** Sprint II Machine Learning & Analytics (40530010056_20230_01)<br>  \n",
        "**Curso:** Ciência de Dados e Analytics<br>  \n",
        "**Instituição:** PUC-Rio<br>\n"
      ],
      "metadata": {
        "id": "VErjNVpOLshL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sprint 02: Machine Learning & Analytics\n",
        "\n",
        "## Definição do Problema\n",
        "\n",
        "Objetivo: Compreender e descrever claramente o problema que está sendo resolvido.\n",
        "\n",
        "Descrição do problema: O problema envolve a segmentação do átrio esquerdo em imagens médicas. Este é um passo fundamental na análise da saúde cardíaca e na detecção de possíveis anormalidades.\n",
        "\n",
        "Premissas ou hipóteses sobre o problema: Estamos assumindo que as etiquetas (labels) fornecidas no conjunto de dados representam com precisão as regiões do átrio esquerdo e do fundo (background) nas imagens.\n",
        "\n",
        "Restrições ou condições impostas para a seleção dos dados: O conjunto de dados fornecido é assumido como representativo da população geral de imagens médicas que o modelo será usado para analisar. Além disso, assumimos que a divisão entre conjuntos de treinamento e teste é razoável e não introduzirá um viés significativo na avaliação do modelo.\n",
        "\n",
        "Descrição do dataset: O conjunto de dados contém imagens rotuladas para treinamento e teste. As etiquetas incluem 'background' e 'left atrium'. O conjunto de dados tem 20 exemplos para treinamento e 10 para teste."
      ],
      "metadata": {
        "id": "8zwGFSMgUWlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importação de bibliotecas\n",
        "\n",
        "Nesta seção, importamos todas as bibliotecas necessárias para o projeto. As bibliotecas numpy e nibabel são usadas para manipular os dados, a biblioteca sklearn.model_selection é usada para dividir os dados em conjuntos de treinamento e teste, e a biblioteca keras é usada para construir e treinar o modelo de deep learning.\n"
      ],
      "metadata": {
        "id": "K_ATPJFbP4G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "!pip install gdown\n",
        "import gdown\n"
      ],
      "metadata": {
        "id": "RQJ0hlC5L4gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download de imagens e rótulos\n",
        "\n",
        "Nesta seção, fazemos o download das imagens e rótulos de treinamento usando o `gdown`. Precisamos fornecer o ID do arquivo no Google Drive e o nome do arquivo com sua extensão. Após o download, carregamos as imagens e rótulos como arrays numpy para facilitar a manipulação posterior.\n",
        "\n"
      ],
      "metadata": {
        "id": "dnsM6ZjyP8Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Substitua 'GOOGLE_DRIVE_FILE_ID_IMAGE' pelo ID do arquivo de imagens no Google Drive\n",
        "# e 'image_filename.extension' pelo nome do arquivo de imagens com sua extensão\n",
        "file_id_image = \"GOOGLE_DRIVE_FILE_ID_IMAGE\"\n",
        "image_filename = \"image_filename.extension\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id_image}\", image_filename)\n",
        "\n",
        "# Substitua 'GOOGLE_DRIVE_FILE_ID_LABEL' pelo ID do arquivo de rótulos no Google Drive\n",
        "# e 'label_filename.extension' pelo nome do arquivo de rótulos com sua extensão\n",
        "file_id_label = \"GOOGLE_DRIVE_FILE_ID_LABEL\"\n",
        "label_filename = \"label_filename.extension\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id_label}\", label_filename)\n"
      ],
      "metadata": {
        "id": "wv3isKWUP79r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento de imagens e rótulos\n",
        "\n",
        "Aqui, carregamos as imagens e rótulos de treinamento usando os caminhos fornecidos no arquivo JSON. As imagens e rótulos são carregados como arrays numpy para facilitar a manipulação posterior.\n"
      ],
      "metadata": {
        "id": "eTo4r9ynQCnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.load(image_filename)\n",
        "labels = np.load(label_filename)\n"
      ],
      "metadata": {
        "id": "aa0LNPHPQCOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação de dados\n",
        "\n",
        "Antes de treinar o modelo, precisamos preparar os dados. Primeiro, normalizamos as imagens para que todos os pixels tenham valores entre 0 e 1. Em seguida, dividimos os dados em conjuntos de treinamento e teste para que possamos avaliar o desempenho do modelo em dados não vistos.\n"
      ],
      "metadata": {
        "id": "41RPQ6vNRkeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = images / np.max(images)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "AtgnLWosRkRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do modelo\n",
        "\n",
        "Aqui, construímos o modelo de deep learning que será usado para a tarefa de segmentação de imagens. Usamos uma arquitetura simples de Rede Neural Convolucional (CNN), que é comumente usada para tarefas de visão computacional. A arquitetura consiste em duas camadas convolucionais, seguidas por uma camada Flatten para transformar os mapas de características 2D em vetores, e finalmente uma camada Dense para a classificação final. A função de ativação 'relu' é usada nas camadas convolucionais para adicionar não linearidade ao modelo, e a função de ativação 'sigmoid' é usada na última camada porque estamos fazendo uma tarefa de classificação binária (segmentação do átrio esquerdo vs. fundo).\n"
      ],
      "metadata": {
        "id": "o-A8Ww-gRrkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape='input_shape'))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "4axawOxzRrbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "Nesta seção, treinamos o modelo usando os dados de treinamento. Também fornecemos os dados de teste ao modelo durante o treinamento para que possamos monitorar o desempenho do modelo em dados não vistos ao longo do tempo.\n"
      ],
      "metadata": {
        "id": "YSJY08d1RsOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n"
      ],
      "metadata": {
        "id": "9P2n8uEzRrR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação do modelo\n",
        "\n",
        "Por fim, avaliamos o desempenho do modelo treinado nos dados de teste. Isso nos dá uma medida final do desempenho do modelo em dados não vistos. Usamos a perda (loss) e a acurácia (accuracy) como métricas de desempenho.\n"
      ],
      "metadata": {
        "id": "FV3Wr7L2RrH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "CElEvmGmRq-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}